{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd3qFh3zvjZZ"
      },
      "source": [
        "1. Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7dlaHw-a7mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58c6f2a-e761-455e-e01e-077deb3340a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install optuna -U -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM6ZrNsLv-0b"
      },
      "outputs": [],
      "source": [
        "# Basic Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.experimental import enable_iterative_imputer  # Enable IterativeImputer\n",
        "from sklearn.impute import IterativeImputer,SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Modeling\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# Evaluation and Splitting\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "# Hyperparameter Optimization\n",
        "import optuna\n",
        "\n",
        "# Utility\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.utils import resample\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7-eCPOlwGJf"
      },
      "source": [
        "2. Load & Merge Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIOC3xv8yU0e"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "train_cat = pd.read_excel('/content/TRAIN_CATEGORICAL_METADATA.xlsx')\n",
        "train_func = pd.read_csv('/content/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
        "train_quant = pd.read_excel('/content/TRAIN_QUANTITATIVE_METADATA.xlsx')\n",
        "train_target = pd.read_excel('/content/TRAINING_SOLUTIONS.xlsx')\n",
        "\n",
        "test_cat = pd.read_excel('/content/TEST_CATEGORICAL.xlsx')\n",
        "test_func = pd.read_csv('/content/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
        "test_quant = pd.read_excel('/content/TEST_QUANTITATIVE_METADATA.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXnLOsS0XJ4U"
      },
      "outputs": [],
      "source": [
        "# prompt: Create a list of train participants and test participants\n",
        "train_participants = train_cat['participant_id'].tolist()  # Assuming 'participant_id' is in train_cat\n",
        "test_participants = test_cat['participant_id'].tolist()  # Assuming 'participant_id' is in test_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsgIMpFDXTX2"
      },
      "outputs": [],
      "source": [
        "# prompt: Delete feature - ''Basic_Demos_Study_Site' from both train and test data\n",
        "\n",
        "# Assuming train_cat and test_cat contain the 'Basic_Demos_Study_Site' column\n",
        "# Delete 'Basic_Demos_Study_Site' from train and test data\n",
        "if 'Basic_Demos_Study_Site' in train_cat.columns:\n",
        "    train_cat = train_cat.drop('Basic_Demos_Study_Site', axis=1)\n",
        "if 'Basic_Demos_Study_Site' in test_cat.columns:\n",
        "    test_cat = test_cat.drop('Basic_Demos_Study_Site', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4elX5mt30WP0",
        "outputId": "c33140ac-f203-4e09-e198-6cc9fbd5a88a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19928, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "var_list = pd.read_csv('/content/VAR_LIST (1) (1).csv')\n",
        "var_list.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_acp-6x3HRZ"
      },
      "outputs": [],
      "source": [
        "categ_vars = var_list.loc[(var_list['label'] == 'categ') & (var_list['var'] != 'Basic_Demos_Study_Site'), 'var'].tolist()\n",
        "quant_vars = var_list.loc[var_list['label'] == 'quant', 'var'].tolist()\n",
        "mri_vars = var_list.loc[var_list['label'] == 'connectome', 'var'].tolist()\n",
        "id_vars = ['participant_id']\n",
        "label_vars = ['ADHD_Outcome',\t'Sex_F',\t'Combined_Outcome']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxFoJcQ53567"
      },
      "outputs": [],
      "source": [
        "# Convert categorical variables to float type in both training and testing datasets.\n",
        "for c in categ_vars:\n",
        "  train_cat[c] = train_cat[c].astype('float') # Changed df_train_cat to train_cat\n",
        "  test_cat[c] = test_cat[c].astype('float') # Changed df_test_cat to test_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsgDk0Ie3q2W"
      },
      "outputs": [],
      "source": [
        "# Merge only the quant and MRI training datasets based on 'participant_id'\n",
        "df_train_merged = train_quant.merge(train_func, how='inner', on='participant_id')\n",
        "df_train_merged = df_train_merged.merge(train_cat, how='inner', on='participant_id')\n",
        "\n",
        "# Merge only the quant and MRI testing datasets based on 'participant_id'\n",
        "df_test_merged = test_quant.merge(test_func, how='inner', on='participant_id')\n",
        "df_test_merged = df_test_merged.merge(test_cat, how='inner', on='participant_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grGezfip4ZtF"
      },
      "outputs": [],
      "source": [
        "# Sort instances in both training and test datasets using participant_id\n",
        "df_train_merged = df_train_merged.sort_values(by=['participant_id']).reset_index(drop=True)\n",
        "df_test_merged = df_test_merged.sort_values(by=['participant_id']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVxlUW19Y4sn"
      },
      "outputs": [],
      "source": [
        "train_target = train_target.sort_values(by=['participant_id']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h_sF_XtQyjQ",
        "outputId": "a98c80da-b4cc-4e55-833d-792dce2d3c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (1213, 19926)\n",
            "y_train shape: (1213, 2)\n",
            "train_stratify length: 1213\n"
          ]
        }
      ],
      "source": [
        "# Ensure consistent participants across features and labels\n",
        "df_train_merged = df_train_merged.sort_values('participant_id')\n",
        "train_target = train_target.sort_values('participant_id')\n",
        "\n",
        "# Keep only common participants\n",
        "common_ids = set(df_train_merged['participant_id']) & set(train_target['participant_id'])\n",
        "df_train_merged = df_train_merged[df_train_merged['participant_id'].isin(common_ids)].reset_index(drop=True)\n",
        "train_target = train_target[train_target['participant_id'].isin(common_ids)].reset_index(drop=True)\n",
        "\n",
        "# Recreate X_train and y_train\n",
        "X_train = df_train_merged.drop(columns=['participant_id'])\n",
        "y_train = train_target[['ADHD_Outcome', 'Sex_F']]\n",
        "\n",
        "# Create stratification variable\n",
        "train_stratify = y_train['ADHD_Outcome'].astype(str) + y_train['Sex_F'].astype(str)\n",
        "\n",
        "# Final check\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"train_stratify length:\", len(train_stratify))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b8hBFpgMv92"
      },
      "outputs": [],
      "source": [
        "# Utility for Stratified K-Fold\n",
        "# n_splits = 5\n",
        "# skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJTG1lWIY5-m"
      },
      "outputs": [],
      "source": [
        "train_stratify = train_target['ADHD_Outcome'].astype('str') + train_target['Sex_F'].astype('str')\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b2wGmNWPzLj"
      },
      "outputs": [],
      "source": [
        "# Prepare the training and testing data by separating features (X) and labels (y).\n",
        "# Ensure that the target variable 'train_stratify' is derived from the same data source as X_train\n",
        "# to avoid the inconsistent number of samples error.\n",
        "\n",
        "# Assuming 'df_train_merged' is the DataFrame used to create X_train:\n",
        "# train_stratify = df_train_merged['ADHD_Outcome'].astype('str') + df_train_merged['Sex_F'].astype('str')  # Derive train_stratify from y_train instead of df_train_merged\n",
        "# train_stratify = y_train['ADHD_Outcome'].astype('str') + y_train['Sex_F'].astype('str') # Use y_train to derive train_stratify\n",
        "\n",
        "# Define y_train before using it to derive train_stratify\n",
        "y_train = train_target[['ADHD_Outcome', 'Sex_F']]  # Extract the target columns from train_target\n",
        "\n",
        "# Now you can use y_train to create train_stratify\n",
        "train_stratify = y_train['ADHD_Outcome'].astype(str) + y_train['Sex_F'].astype(str)\n",
        "\n",
        "# Now proceed with creating X_train and y_train as before:\n",
        "X_train = df_train_merged.iloc[:, 1:].reset_index(drop=True)\n",
        "X_test = df_test_merged.iloc[:, 1:].reset_index(drop=True)\n",
        "\n",
        "# ... rest of your code ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6cN5bzKZ0Mv"
      },
      "outputs": [],
      "source": [
        "# Initialize arrays to store out-of-fold and test predictions for ADHD and sex.\n",
        "oof_preds_adhd = np.zeros(X_train.shape[0])\n",
        "oof_preds_sex = np.zeros(X_train.shape[0])\n",
        "test_preds_adhd = np.zeros(X_test.shape[0])\n",
        "test_preds_sex = np.zeros(X_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1ijfKfwaHvG"
      },
      "outputs": [],
      "source": [
        "# Get indices of categorical and numerical variables.\n",
        "categ_vars_inds = [X_train.columns.get_loc(col) for col in categ_vars]\n",
        "all_num_vars_inds = [X_train.columns.get_loc(col) for col in quant_vars + mri_vars]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kP7NBx-wd8v1"
      },
      "outputs": [],
      "source": [
        "preprocessor_imputer = ColumnTransformer(transformers=[\n",
        "  ('num_imputer', IterativeImputer(\n",
        "      estimator=LinearRegression(),\n",
        "      max_iter=20,\n",
        "      n_nearest_features=500,\n",
        "      initial_strategy='mean',\n",
        "      random_state=123,\n",
        "      skip_complete=True,\n",
        "      tol=1e-2), all_num_vars_inds\n",
        "   ),\n",
        "  ('categ_imputer_01', SimpleImputer(strategy='constant', fill_value=3), [categ_vars_inds[0]]),\n",
        "  ('categ_imputer_02', SimpleImputer(strategy='constant', fill_value=10), [categ_vars_inds[1]]),\n",
        "  ('categ_imputer_03', SimpleImputer(strategy='constant', fill_value=99), [categ_vars_inds[2]]),\n",
        "  ('categ_imputer_04', SimpleImputer(strategy='constant', fill_value=99), [categ_vars_inds[3]]),\n",
        "  ('categ_imputer_05', SimpleImputer(strategy='constant', fill_value=99), [categ_vars_inds[4]]),\n",
        "  ('categ_imputer_06', SimpleImputer(strategy='constant', fill_value=99), [categ_vars_inds[5]]),\n",
        "  ('categ_imputer_07', SimpleImputer(strategy='constant', fill_value=99), [categ_vars_inds[6]])\n",
        "], remainder='passthrough')\n",
        "\n",
        "\n",
        "preprocessor_pca_encoding = ColumnTransformer(transformers=[\n",
        "    ('pca', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=0.95))]), all_num_vars_inds),\n",
        "    ('onehotencoder', OneHotEncoder(), categ_vars_inds)\n",
        "], remainder='passthrough')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvWJPAPvenG6"
      },
      "outputs": [],
      "source": [
        "preprocessor_pipeline_imputer = Pipeline([\n",
        "  ('preprocessor_imputer', preprocessor_imputer)\n",
        "])\n",
        "\n",
        "\n",
        "preprocessor_pipeline_encoding = Pipeline([\n",
        "  ('preprocessor_pca_encoding', preprocessor_pca_encoding)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z3HT9JSghiD"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier  # only used for importance modeling\n",
        "from xgboost import XGBClassifier # import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTENC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G87vTXkLTk6C"
      },
      "outputs": [],
      "source": [
        "# List of models for ensemble\n",
        "models = [\n",
        "    MultiOutputClassifier(LGBMClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, num_leaves=15, random_state=123, n_jobs=-1)),\n",
        "    MultiOutputClassifier(XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, subsample=0.7, colsample_bytree=0.7, random_state=123)),\n",
        "    MultiOutputClassifier(GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=123)),\n",
        "    MultiOutputClassifier(LogisticRegression(penalty='l2', random_state=123))  # Changed penalty to 'l2' for Ridge regularization\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILTfxtItOWrg",
        "outputId": "6a1d494a-f317-4958-d3df-d28e76d65724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 928, number of negative: 928\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023919 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 180124\n",
            "[LightGBM] [Info] Number of data points in the train set: 1856, number of used features: 753\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 928, number of negative: 928\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034543 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 180124\n",
            "[LightGBM] [Info] Number of data points in the train set: 1856, number of used features: 753\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 930, number of negative: 930\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032436 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 179359\n",
            "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 750\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 930, number of negative: 930\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027491 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 179359\n",
            "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 750\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 930, number of negative: 930\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023789 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 179357\n",
            "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 749\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 930, number of negative: 930\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033350 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 179357\n",
            "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 749\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 930, number of negative: 930\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036291 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 179104\n",
            "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 749\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 930, number of negative: 930\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033493 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 179104\n",
            "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 749\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 930, number of negative: 930\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036893 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 179357\n",
            "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 749\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 930, number of negative: 930\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032172 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 179357\n",
            "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 749\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Training loop with cross-validation\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, train_stratify)):\n",
        "    print(f'\\nFold {fold + 1}')\n",
        "\n",
        "    # Split train/val data\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    # Preprocess: Imputation + Scaling\n",
        "    X_tr_processed = preprocessor_pipeline_imputer.fit_transform(X_tr)\n",
        "    X_val_processed = preprocessor_pipeline_imputer.transform(X_val)\n",
        "    X_test_processed = preprocessor_pipeline_imputer.transform(X_test)\n",
        "\n",
        "    # Upsample minority using SMOTENC\n",
        "    tr_stratify = y_tr['ADHD_Outcome'].astype(str) + y_tr['Sex_F'].astype(str)\n",
        "    smote_nc = SMOTENC(categorical_features=categ_vars_inds, random_state=123)\n",
        "    X_tr_resampled, y_strat_combined = smote_nc.fit_resample(X_tr_processed, tr_stratify)\n",
        "\n",
        "    y_tr_resampled = pd.DataFrame({\n",
        "        'ADHD_Outcome': y_strat_combined.str[0].astype(int),\n",
        "        'Sex_F': y_strat_combined.str[1].astype(int)\n",
        "    })\n",
        "\n",
        "    # One-hot encode and transform\n",
        "    X_tr_resampled = preprocessor_pipeline_encoding.fit_transform(X_tr_resampled)\n",
        "    X_val_processed = preprocessor_pipeline_encoding.transform(X_val_processed)\n",
        "    X_test_processed = preprocessor_pipeline_encoding.transform(X_test_processed)\n",
        "\n",
        "    # Arrays to hold the predictions for each model\n",
        "    val_preds_all = []\n",
        "    test_preds_all = []\n",
        "\n",
        "    # Loop through models to train and make predictions\n",
        "    for model in models:\n",
        "        model.fit(X_tr_resampled, y_tr_resampled)\n",
        "\n",
        "        # Get out-of-fold predictions\n",
        "        val_preds_all.append(model.predict_proba(X_val_processed))\n",
        "\n",
        "        # Get test predictions\n",
        "        test_preds_all.append(model.predict_proba(X_test_processed))\n",
        "\n",
        "    # Average the predicted probabilities for each target across all models\n",
        "    avg_val_preds = [np.mean([p[i][:, 1] for p in val_preds_all], axis=0) for i in range(2)]\n",
        "    avg_test_preds = [np.mean([p[i][:, 1] for p in test_preds_all], axis=0) for i in range(2)]\n",
        "\n",
        "    # Store the averaged predictions\n",
        "    oof_preds_adhd[val_idx] = avg_val_preds[0]\n",
        "    oof_preds_sex[val_idx] = avg_val_preds[1]\n",
        "    test_preds_adhd += avg_test_preds[0] / skf.n_splits\n",
        "    test_preds_sex += avg_test_preds[1] / skf.n_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJN36pIZg5ks"
      },
      "outputs": [],
      "source": [
        "def weighted_f1_score(y_true_adhd, y_pred_adhd, y_true_sex, y_pred_sex):\n",
        "  weights = [2 if (a == 1 and s == 1) else 1\n",
        "          for a, s in zip(y_true_adhd, y_true_sex)]\n",
        "\n",
        "  def compute_f1(y_true, y_pred, weights):\n",
        "      TP = sum(w for i, w in enumerate(weights) if y_true[i] == 1 and y_pred[i] == 1)\n",
        "      FP = sum(w for i, w in enumerate(weights) if y_true[i] == 0 and y_pred[i] == 1)\n",
        "      FN = sum(w for i, w in enumerate(weights) if y_true[i] == 1 and y_pred[i] == 0)\n",
        "\n",
        "      if TP + FP == 0 or TP + FN == 0:\n",
        "          return 0.0\n",
        "\n",
        "      precision = TP / (TP + FP)\n",
        "      recall = TP / (TP + FN)\n",
        "      if precision + recall == 0:\n",
        "          return 0.0\n",
        "      f1 = 2 * precision * recall / (precision + recall)\n",
        "      return f1\n",
        "\n",
        "  f1_adhd = compute_f1(y_true_adhd, y_pred_adhd, weights)\n",
        "  f1_sex = compute_f1(y_true_sex, y_pred_sex, weights)\n",
        "\n",
        "  # Final F1 on the leaderboard\n",
        "  return (f1_adhd + f1_sex) / 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold optimization and final predictions as you've done\n",
        "thresholds = np.linspace(0, 1, 101)\n",
        "best_score = 0\n",
        "best_t1 = 0\n",
        "best_t2 = 0\n",
        "score_val, t1_val, t2_val = [], [], []"
      ],
      "metadata": {
        "id": "qkOq3hx1eMh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnR5a3ELooQY"
      },
      "outputs": [],
      "source": [
        "y_adhd = y_train['ADHD_Outcome']\n",
        "y_sex = y_train['Sex_F']\n",
        "\n",
        "probs_adhd = oof_preds_adhd\n",
        "probs_sex = oof_preds_sex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL4-5UlWorSl"
      },
      "outputs": [],
      "source": [
        "for t1 in thresholds:\n",
        "  for t2 in thresholds:\n",
        "    preds_adhd = (probs_adhd >= t1).astype(int)\n",
        "    preds_sex = (probs_sex >= t2).astype(int)\n",
        "\n",
        "    weighted_f1  = weighted_f1_score(y_adhd, preds_adhd, y_sex, preds_sex)\n",
        "    score_val.append(weighted_f1)\n",
        "    t1_val.append(t1)\n",
        "    t2_val.append(t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvKGbmZIowrc"
      },
      "outputs": [],
      "source": [
        "df_scores = pd.DataFrame({'f1': score_val, 't1': t1_val, 't2': t2_val})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajMJOpJkprin"
      },
      "outputs": [],
      "source": [
        "df_scores = df_scores.sort_values(by='f1', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "edgJHXA3puET",
        "outputId": "883a13e7-884d-464d-c69f-e01655c000c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            f1    t1    t2\n",
              "1535  0.751632  0.15  0.20\n",
              "1534  0.751576  0.15  0.19\n",
              "1333  0.751524  0.13  0.20\n",
              "222   0.751474  0.02  0.20\n",
              "727   0.751474  0.07  0.20\n",
              "626   0.751474  0.06  0.20\n",
              "525   0.751474  0.05  0.20\n",
              "121   0.751474  0.01  0.20\n",
              "424   0.751474  0.04  0.20\n",
              "323   0.751474  0.03  0.20\n",
              "20    0.751474  0.00  0.20\n",
              "1332  0.751468  0.13  0.19\n",
              "221   0.751419  0.02  0.19\n",
              "524   0.751419  0.05  0.19\n",
              "120   0.751419  0.01  0.19\n",
              "726   0.751419  0.07  0.19\n",
              "423   0.751419  0.04  0.19\n",
              "625   0.751419  0.06  0.19\n",
              "322   0.751419  0.03  0.19\n",
              "19    0.751419  0.00  0.19\n",
              "1131  0.751415  0.11  0.20\n",
              "1130  0.751360  0.11  0.19\n",
              "1434  0.751297  0.14  0.20\n",
              "828   0.751248  0.08  0.20\n",
              "1030  0.751248  0.10  0.20\n",
              "929   0.751248  0.09  0.20\n",
              "1433  0.751241  0.14  0.19\n",
              "1029  0.751193  0.10  0.19\n",
              "928   0.751193  0.09  0.19\n",
              "827   0.751193  0.08  0.19\n",
              "1232  0.751189  0.12  0.20\n",
              "1536  0.751142  0.15  0.21\n",
              "1231  0.751134  0.12  0.19\n",
              "1533  0.751131  0.15  0.18\n",
              "1636  0.751119  0.16  0.20\n",
              "1635  0.751063  0.16  0.19\n",
              "1334  0.751033  0.13  0.21\n",
              "1331  0.751023  0.13  0.18\n",
              "223   0.750984  0.02  0.21\n",
              "425   0.750984  0.04  0.21\n",
              "526   0.750984  0.05  0.21\n",
              "728   0.750984  0.07  0.21\n",
              "122   0.750984  0.01  0.21\n",
              "324   0.750984  0.03  0.21\n",
              "21    0.750984  0.00  0.21\n",
              "627   0.750984  0.06  0.21\n",
              "119   0.750974  0.01  0.18\n",
              "725   0.750974  0.07  0.18\n",
              "321   0.750974  0.03  0.18\n",
              "523   0.750974  0.05  0.18"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea8523e0-a91f-4b19-a1d1-4eedb1bb0aae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>t1</th>\n",
              "      <th>t2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1535</th>\n",
              "      <td>0.751632</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1534</th>\n",
              "      <td>0.751576</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>0.751524</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>0.751474</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>0.751474</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>0.751474</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>0.751474</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>0.751474</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>0.751474</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.751474</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.751474</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1332</th>\n",
              "      <td>0.751468</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>0.751419</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>0.751419</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.751419</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>0.751419</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>0.751419</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>0.751419</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>0.751419</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.751419</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1131</th>\n",
              "      <td>0.751415</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>0.751360</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1434</th>\n",
              "      <td>0.751297</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>0.751248</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030</th>\n",
              "      <td>0.751248</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>0.751248</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1433</th>\n",
              "      <td>0.751241</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>0.751193</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928</th>\n",
              "      <td>0.751193</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>0.751193</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>0.751189</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1536</th>\n",
              "      <td>0.751142</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>0.751134</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1533</th>\n",
              "      <td>0.751131</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1636</th>\n",
              "      <td>0.751119</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1635</th>\n",
              "      <td>0.751063</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>0.751033</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1331</th>\n",
              "      <td>0.751023</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>0.750984</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>0.750984</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>0.750984</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>0.750984</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>0.750984</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>0.750984</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.750984</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>0.750984</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.750974</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>0.750974</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.750974</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>0.750974</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea8523e0-a91f-4b19-a1d1-4eedb1bb0aae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea8523e0-a91f-4b19-a1d1-4eedb1bb0aae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea8523e0-a91f-4b19-a1d1-4eedb1bb0aae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8ef5a480-d6c5-43ca-877f-6f2cb982b457\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ef5a480-d6c5-43ca-877f-6f2cb982b457')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8ef5a480-d6c5-43ca-877f-6f2cb982b457 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_scores\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00020815653290564542,\n        \"min\": 0.7509735946227587,\n        \"max\": 0.7516319154803052,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.7516319154803052,\n          0.7511415041743414,\n          0.751296943955992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05023048915565452,\n        \"min\": 0.0,\n        \"max\": 0.16,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.15,\n          0.13,\n          0.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009452350965527585,\n        \"min\": 0.18,\n        \"max\": 0.21,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.19,\n          0.18,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df_scores.iloc[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7-29ev6qnBc"
      },
      "outputs": [],
      "source": [
        "t_adhd = df_scores.iloc[:50, 1].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LG5n81jqvFv"
      },
      "outputs": [],
      "source": [
        "t_sex = df_scores.iloc[:50, 2].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zgoo5TsqxEY"
      },
      "outputs": [],
      "source": [
        "preds_test_adhd = (test_preds_adhd >= t_adhd).astype(int)\n",
        "preds_test_sex = (test_preds_sex >= t_sex).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7yval74q4GY"
      },
      "outputs": [],
      "source": [
        "final = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnV8gRvLq5zx"
      },
      "outputs": [],
      "source": [
        "final['participant_id'] = df_test_merged['participant_id']\n",
        "final['Sex_F'] = preds_test_sex\n",
        "final['ADHD_Outcome'] = preds_test_adhd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP-KPqHWq7b3"
      },
      "outputs": [],
      "source": [
        "final.to_csv('EnsembleClassifier_30Apr.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4TyTYu2rBkG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}